# 多模态大模型

### 如何判断、缓解过拟合：
判断：
1. 看训练集测试集的表现差异，如果训练集上表现很好，测试集上表现很差，则模型可能过拟合了
2. 看模型的学习曲线，过拟合的模型训练曲线可能会一直下降，验证集的学习曲线会先下降然后在某一个节点开始上升
缓解：
1. 数据增强，增加数据的多样性
2. 减少模型的复杂度，包括减少模型的层数、降低特征的纬度
3. 正则化技术。L1正则化、L2正则化通过在损失函数里加入权重惩罚。L1正则化可以使权重参数训练为0，从而达到模型稀疏的目的。L2正则化会对大的参数惩罚力度大，更适合防止过拟合。Dropout技术，在训练过程中随机关闭一部分参数
4. 调整学习率
5. 早停法：查看验证集的学习曲线，当损失不再下降时停止训练
6. k折交叉验证，将训练集分为k折，每次取其中k-1折进行训练，另外一个折做测试。

### BN和LN是什么，为什么需要它们
BN是Batch Normalization，它是对一个batch的每个特征进行标准化处理；LN是Layer Normalization，它是对每个样本的所有特征进行标准化处理。BN,LN的目的是为了使每层的输入数据满足均值为0，方差为1的分布。
作用：
1. 防止梯度消失、梯度爆炸。在反向传播计算梯度的时候，梯度的大小与输入有关，如果输入过大或过小，任意导致梯度消失或梯度爆炸的问题。
2. 加速模型收敛。某一层的输入会随着前面层参数变化而变化（内部内部协变量偏移），通过加入标准化，输入的分布趋于稳定，网络更加稳定。
3. 减低超参数的敏感度
4. 防止过拟合

由于BN计算均值和标准差时，依赖batch的大小，太小的batch会不准。若输入的是序列数据，样本长度不一致时，也无法使用BN。BN通常假设样本之间是独立同分布的，而对于序列数据一般有依赖关系，因此这些情况更适合使用LN


